{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "chatbot_v7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VGGatGitHub/AnswerFlow/blob/master/chatbot_v7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIF2hQ5wGsqg",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/datasets?search=nq-train\n",
        "\n",
        "V2: added comads to look at the structure of the train.json file and to assess the %s.\n",
        "\n",
        "V3: changing the code to do tarining for long_answesrs or short_answers using training_for_long_answer switch.\n",
        "\n",
        "V4: reading in json file produced from jsonl using jsonl2json.ipynb\n",
        "\n",
        "V6: reading files from GitHub\n",
        "\n",
        "V7: using similarity function to assess the new answers \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xPDM8ocY74i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG in case of using the Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ed-1NnYIGsqj",
        "colab_type": "code",
        "outputId": "0edc7f8d-4a03-4db6-9092-e785d025e2bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys \n",
        "import os\n",
        "print(os.getcwd())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QByI39lkVt8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG define the foldre to inspect for files \n",
        "\n",
        "#path='/content/drive/My Drive/Colab Notebooks/'\n",
        "path=os.getcwd()+\"/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_S1byB1WPph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG read in training data\n",
        "#you may have to adjust the BATCH_SIZE acordingly \n",
        "file_name='train25.json' #or train25.json or train200.json \n",
        "\n",
        "\n",
        "file_to_read=path+file_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCUwJWTEms7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Geting the training data file \n",
        "\n",
        "import requests\n",
        "\n",
        "#if file_name == 'train1k.json':\n",
        "#  file_url='https://drive.google.com/file/d/1dJv_ddm5Fv7TYhsEQIGTsmDN0yYbSn5y/view?ts=5e06f6fb'\n",
        "#else:\n",
        "\n",
        "file_url='https://raw.githubusercontent.com/VGGatGitHub/natural-questions/master/'+file_name\n",
        "\n",
        "rqstgt = requests.get(file_url)\n",
        "\n",
        "s=rqstgt.content\n",
        "# Code for printing to a file \n",
        "sample = open(file_to_read, 'w') \n",
        "doc=s.decode()\n",
        "print(doc, file = sample) \n",
        "sample.close() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3ej-f3iYGsqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "cea030c2-36aa-4d09-e7a9-ee6ce3050642"
      },
      "source": [
        "#make sure the file you what is in the correct directory\n",
        "#some possible files are train.json or train200.json \n",
        "\n",
        "for dirname, _, filenames in os.walk(path):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/train25.json\n",
            "/content/train200.json\n",
            "/content/.config/.last_update_check.json\n",
            "/content/.config/active_config\n",
            "/content/.config/.last_survey_prompt.yaml\n",
            "/content/.config/config_sentinel\n",
            "/content/.config/gce\n",
            "/content/.config/.metricsUUID\n",
            "/content/.config/configurations/config_default\n",
            "/content/.config/logs/2019.12.18/16.52.31.147337.log\n",
            "/content/.config/logs/2019.12.18/16.52.34.414154.log\n",
            "/content/.config/logs/2019.12.18/16.52.05.166856.log\n",
            "/content/.config/logs/2019.12.18/16.52.35.435000.log\n",
            "/content/.config/logs/2019.12.18/16.52.20.616768.log\n",
            "/content/sample_data/README.md\n",
            "/content/sample_data/anscombe.json\n",
            "/content/sample_data/mnist_train_small.csv\n",
            "/content/sample_data/california_housing_test.csv\n",
            "/content/sample_data/mnist_test.csv\n",
            "/content/sample_data/california_housing_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS2xGhZCoFxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG\n",
        "# you may need to get the file text_utils.py from \n",
        "# https://github.com/VGGatGitHub/natural-questions\n",
        "#\n",
        "\n",
        "# sys.path.append(os.path.abspath(path))\n",
        "# from text_utils import *\n",
        "\n",
        "# got import errors on colab using import code above\n",
        "# import text_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EhFsBX5aKR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG The cell has been removed since now the data is analized in the jsonl2json.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pgXArJmIaiv",
        "colab_type": "code",
        "outputId": "f0cf1ec0-2203-4b7c-9400-7af904b838ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7bPY5ic2eC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (0-9, a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^0-9a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbW-oSFI2mFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG make sure the file_to_read has been defined above! \n",
        "\n",
        "UNKNOWN = \"<UNKNOWN>\"\n",
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset():\n",
        "    source = []\n",
        "    target = []\n",
        "    context = []\n",
        "\n",
        "    n_short_answers=0 #VGG\n",
        "    n_long=0\n",
        "    \n",
        "    training_for_long_answer = False #True #False \n",
        "    #make sure to run furst for shor answers and then for long...\n",
        "\n",
        "    with open(file_to_read) as json_file: #VGG\n",
        "        data = json.load(json_file)\n",
        "\n",
        "        for nq_doc in data:\n",
        "            if filename == 'train200L.json':\n",
        "              doc = simplify_nq_example(nq_doc) #VGG for jsonl formated file\n",
        "            else:\n",
        "              doc=nq_doc\n",
        "\n",
        "            question_text = doc['question_text']\n",
        "            document_text = doc['document_text'].split()\n",
        "            long_answer_candidates = doc['long_answer_candidates']\n",
        "            annotations = doc['annotations'][0]\n",
        "            \n",
        "            if annotations['long_answer']['start_token'] < annotations['long_answer']['end_token']:\n",
        "                \n",
        "                n_long+=1\n",
        "                long_answer = \" \".join(document_text[annotations['long_answer']['start_token']:\n",
        "                                                     annotations['long_answer']['end_token']])\n",
        "                                      \n",
        "                if len(annotations['short_answers']) > 0:\n",
        "                    start_token = annotations['short_answers'][0]['start_token']\n",
        "                    end_token = annotations['short_answers'][0]['end_token']\n",
        "                    short_answer = \" \".join(document_text[start_token:end_token])\n",
        "                    n_short_answers+=1 #VGG\n",
        "                else:\n",
        "                    short_answer = UNKNOWN\n",
        "                \n",
        "                #VGG V3\n",
        "                if training_for_long_answer :\n",
        "                    short_answer=long_answer #VGG V3 change - make the target to be the long answer instead of the short answer \n",
        "                    for posibilities in long_answer_candidates:\n",
        "                        if posibilities[\"top_level\"]:\n",
        "                            start_token = posibilities['start_token']\n",
        "                            end_token = posibilities['end_token']                    \n",
        "                            posibility = \" \".join(document_text[start_token:end_token])\n",
        "                            context.append(preprocess_sentence(posibility))\n",
        "                else:\n",
        "                    context.append(preprocess_sentence(long_answer))\n",
        "                #VGG \n",
        "                context = [] #VGG it seems to work better!\n",
        "\n",
        "                source.append(preprocess_sentence(question_text))\n",
        "                target.append(preprocess_sentence(short_answer))\n",
        "#VGG                \n",
        "        print(\"Data set of:\",len(data),\" elements. It contains:\",\n",
        "              n_short_answers,\"short answers out of\", n_long,\n",
        "              \"possible long answers, short/long rate is {:.0f}%\".format(\n",
        "                  100*n_short_answers/n_long))    \n",
        "    return target, source, context\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4ecf3676-acd1-45e5-9459-3f9030b8b059",
        "_cell_guid": "3f83746e-4fa4-4e24-98cb-2f0df139a6af",
        "trusted": true,
        "id": "jevAjFFiGsqr",
        "colab_type": "code",
        "outputId": "db8b1126-eea4-4ead-935f-3d3704713d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "    \n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "  return tensor, lang_tokenizer\n",
        "\n",
        "def load_dataset():\n",
        "    # creating cleaned input, output pairs\n",
        "    targ_lang, inp_lang, context_lang = create_dataset()\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "    \n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n",
        "\n",
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n",
        "    \n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "    \n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights\n",
        "\n",
        "# Try experimenting with the size of that dataset\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset()\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)    \n",
        "\n",
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 5 #VGG\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 512\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)    \n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "    \n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ = tf.multiply(loss_, mask)\n",
        "  return tf.reduce_mean(loss_)\n",
        "\n",
        "\n",
        "#VGG uncommented for possible checkpoint saving later \n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)  \n",
        "\n",
        "                                 \n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "  return batch_loss\n",
        "  \n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word_index.get(i, 0) for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                           maxlen=max_length_inp,\n",
        "                                                           padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    result ='<start> '#VGG \n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result, sentence, attention_plot\n",
        "    \n",
        "#If you get error message about iretation problem -  check your BATCH_SIZE"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data set of: 25  elements. It contains: 10 short answers out of 17 possible long answers, short/long rate is 59%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OMsxPEhOGsqt",
        "colab_type": "code",
        "outputId": "dbf39e82-1a95-42dc-9a89-91346c488df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "epoch=-1\n",
        "total_loss=1\n",
        "total_loss_cut=0.001*steps_per_epoch*BATCH_SIZE\n",
        "training_start_time=time.time()\n",
        "\n",
        "print(\"\\nStarting training of at most {} epochs or until total loss is les than {:0.4f}\".format(EPOCHS,total_loss_cut))\n",
        "while (epoch < EPOCHS) and (total_loss > total_loss_cut):\n",
        "  epoch+=1\n",
        "\n",
        "  start = time.time()\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch%8 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "  '''\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "  '''   \n",
        "\n",
        "  print('Epoch {} Total Loss {:.4f}'.format(epoch + 1, total_loss))\n",
        "  print('Time taken for this epoch {:.4f} sec\\n'.format(time.time() - start))\n",
        "\n",
        "print('BATCH_SIZE:{}, total traing time {:.2f} minutes for {} epochs, final total_loss {:.4f}\\n'.format(\n",
        "    BATCH_SIZE,(time.time() - training_start_time)/60,epoch+1,total_loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training of at most 100 epochs or until total loss is les than 0.0100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG-iceMSrYNF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "05edcb27-d1a5-4a62-a8bd-2afed0c117d7"
      },
      "source": [
        "print('BATCH_SIZE:{}, total traing time {:.2f} minutes for {} epochs, final total_loss {:.4f}\\n'.format(\n",
        "    BATCH_SIZE,(time.time() - training_start_time)/60,epoch+1,total_loss))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BATCH_SIZE:5, total traing time 7.26 minutes for 47 epochs, final total_loss 0.0092\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iI09zf-bGsqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    fontdict = {'fontsize': 14}\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()\n",
        "\n",
        "def ask(sentence):\n",
        "    result, sentence1, attention_plot = evaluate(sentence)\n",
        "    print('\\nQuestion: %s' % (sentence))\n",
        "    print('Predicted answer: {}'.format(result))\n",
        "    return result\n",
        "\n",
        "def show_attention_plot(sentence):\n",
        "  result, sentence1, attention_plot = evaluate(sentence)\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
        "\n",
        "def is_it_known(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "    if result.split() != ['<start>', 'unknown', '<end>']: return True\n",
        "    return False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7a7fe15c-ca68-49f0-bec9-059d7ef47e6a",
        "_cell_guid": "4684e38d-ab84-492d-8e2f-d13b1a0924fd",
        "trusted": true,
        "id": "4hRJh7EFGsqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "68d4aef5-84f8-4995-b40e-c2c856dc8ee0"
      },
      "source": [
        "ask('which is the most common use of opt-in e-mail marketing')    \n",
        "ask('most common use of opt-in e-mail marketing')\n",
        "ask('how did I meet your mother')\n",
        "ask('who is your mother');\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question: which is the most common use of opt-in e-mail marketing\n",
            "Predicted answer: <start> unknown <end> \n",
            "\n",
            "Question: most common use of opt-in e-mail marketing\n",
            "Predicted answer: <start> unknown <end> \n",
            "\n",
            "Question: how did I meet your mother\n",
            "Predicted answer: <start> unknown <end> \n",
            "\n",
            "Question: who is your mother\n",
            "Predicted answer: <start> unknown <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkzhBscq3zWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "c7550a6e-78a0-4aa4-9ea2-5caa87b5f67a"
      },
      "source": [
        "show_attention_plot(\"which is the most common use of opt in e mail marketing\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoMAAAEaCAYAAABq712YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VbL6X2bzGsq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "c309fb30-d4b5-4272-cd82-6cafb0feb6a4"
      },
      "source": [
        "show_attention_plot(\"who plays young flo in the progressive commercials\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoMAAAGJCAYAAADxHTl1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEdV3whqoTty",
        "colab_type": "code",
        "outputId": "d000af9a-f263-4940-b842-ed8c2fa05794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_md\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_fGaAGKoVLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy as sp\n",
        "nlp = sp.load(\"en_core_web_md\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IigyUmaoX3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test the similarity measure and get some idea about the output values \n",
        "\n",
        "# sample text\n",
        "messages = [\n",
        "# Smartphones\n",
        "\"My phone is not good.\",\n",
        "\"Your cellphone looks great.\",\n",
        "# Weather\n",
        "\"Will it snow tomorrow?\",\n",
        "\"Recently a lot of hurricanes have hit the US\",\n",
        "# Food and health\n",
        "\"An apple a day, keeps the doctors away\",\n",
        "\"Eating strawberries is healthy\"\n",
        "]\n",
        "\n",
        "for text1 in messages:\n",
        "  doc1 = nlp(text1)\n",
        "  print()\n",
        "  for text2 in messages:\n",
        "    doc2 = nlp(text2)\n",
        "    print(doc1.similarity(doc2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iRhZwdJrWPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "ecd3fe3d-bce4-4ef6-9b21-f33759b2bc46"
      },
      "source": [
        "target, source, context = create_dataset()\n",
        "\n",
        "print(\"\\ngoing over all the questions and selecting those with answers ... \\n\")\n",
        "\n",
        "n_answers=0\n",
        "i=-1\n",
        "n_correct=0\n",
        "n_smlr=0\n",
        "smlrty_cut=85\n",
        "for question_text in source:\n",
        "    i+=1\n",
        "    TheAnswer=target[i]\n",
        "    TheAnswer=TheAnswer.replace('<start>',' ')\n",
        "    TheAnswer=TheAnswer.replace('<end>',' ')\n",
        "    doc1 = nlp(TheAnswer)\n",
        "    if is_it_known(question_text):\n",
        "        n_answers+=1\n",
        "        AFanswer=ask(question_text)\n",
        "        AFanswer=AFanswer.replace('<start>',' ')\n",
        "        AFanswer=AFanswer.replace('<end>',' ')\n",
        "        doc2 = nlp(AFanswer)\n",
        "        if AFanswer.split() == TheAnswer.split(): \n",
        "          n_correct+=1\n",
        "        else:\n",
        "          smlrty=100*doc1.similarity(doc2)\n",
        "          if smlrty > smlrty_cut: n_smlr+=1\n",
        "          print(\"The answer was:\",target[i])\n",
        "          print(\"Similarity:{:0.2f}%\\n\".format(smlrty))\n",
        "\n",
        "print(\"\\n{} answers out of {} possible, rate is {:.0f}%\".format(n_answers,len(source),100*n_answers/len(source)))\n",
        "if n_answers >0:\n",
        "  print(\"At least {} correct answers out of {} possible, rate is {:.0f}%\".format(n_correct,n_answers,100*n_correct/n_answers))\n",
        "if n_smlr >0:\n",
        "  print(\"There were {} similar answers with  similarity above {}%\\n\".format(n_smlr,smlrty_cut))\n",
        "           "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data set of: 25  elements. It contains: 10 short answers out of 17 possible long answers, short/long rate is 59%\n",
            "\n",
            "going over all the questions and selecting those with answers ... \n",
            "\n",
            "\n",
            "Question: <start> when is the last episode of season 8 of the walking dead <end>\n",
            "Predicted answer: <start> the shulchan aruch <end> \n",
            "The answer was: <start> march 18 , 2018 <end>\n",
            "Similarity:14.81%\n",
            "\n",
            "\n",
            "Question: <start> in greek mythology who was the goddess of spring growth <end>\n",
            "Predicted answer: <start> persephone p r s f ni greek , also called kore k ri the maiden <end> \n",
            "\n",
            "Question: <start> what is the name of the most important jewish text <end>\n",
            "Predicted answer: <start> real madrid <end> \n",
            "The answer was: <start> the shulchan aruch <end>\n",
            "Similarity:31.12%\n",
            "\n",
            "\n",
            "Question: <start> what is the name of spain s most famous soccer team <end>\n",
            "Predicted answer: <start> real madrid <end> \n",
            "\n",
            "Question: <start> when was the first robot used in surgery <end>\n",
            "Predicted answer: <start> shmi <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The answer was: <start> 1983 <end>\n",
            "Similarity:0.00%\n",
            "\n",
            "\n",
            "Question: <start> who sings the song i don t care i love it <end>\n",
            "Predicted answer: <start> persephone p r s f ni greek , also called kore k ri the maiden <end> \n",
            "The answer was: <start> icona pop and charli xcx <end>\n",
            "Similarity:34.20%\n",
            "\n",
            "\n",
            "6 answers out of 17 possible, rate is 35%\n",
            "At least 2 correct answers out of 6 possible, rate is 33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXQ0s6F9nsH9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fca7428d-3187-4be0-a821-606253266281"
      },
      "source": [
        "target, source, context = create_dataset()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data set of: 25  elements. It contains: 10 short answers out of 17 possible long answers, short/long rate is 59%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyw_WyJB0tZ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a55d8af4-2011-4c2a-a0dc-84716e30117f"
      },
      "source": [
        "print(\"Short Answer traning results:\")\n",
        "print(\"\\n{} answers out of {} possible, rate is {:.0f}%\".format(n_answers,len(source),100*n_answers/len(source)))\n",
        "if n_answers >0:\n",
        "  print(\"At least {} correct answers out of {} possible, rate is {:.0f}%\".format(n_correct,n_answers,100*n_correct/n_answers))\n",
        "if n_smlr >0:\n",
        "  print(\"There were {} similar answers with  similarity above {}%\\n\".format(n_smlr,smlrty_cut))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Short Answer traning results:\n",
            "\n",
            "6 answers out of 17 possible, rate is 35%\n",
            "At least 2 correct answers out of 6 possible, rate is 33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w3K2RVX1AuD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "065d3aef-ba0b-4fbe-d339-93835cc5f3ca"
      },
      "source": [
        "print(\"Long Answer traning results:\")\n",
        "print(\"\\n{} answers out of {} possible, rate is {:.0f}%\".format(n_answers,len(source),100*n_answers/len(source)))\n",
        "if n_answers >0:\n",
        "  print(\"At least {} correct answers out of {} possible, rate is {:.0f}%\".format(n_correct,n_answers,100*n_correct/n_answers))\n",
        "if n_smlr >0:\n",
        "  print(\"There were {} similar answers with  similarity above {}%\\n\".format(n_smlr,smlrty_cut))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Long Answer traning results:\n",
            "\n",
            "6 answers out of 17 possible, rate is 35%\n",
            "At least 2 correct answers out of 6 possible, rate is 33%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}