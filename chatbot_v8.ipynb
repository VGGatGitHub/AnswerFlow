{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "chatbot_v7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VGGatGitHub/AnswerFlow/blob/master/chatbot_v8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIF2hQ5wGsqg",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/datasets?search=nq-train\n",
        "\n",
        "V2: added comads to look at the structure of the train.json file and to assess the %s.\n",
        "\n",
        "V3: changing the code to do tarining for long_answesrs or short_answers using training_for_long_answer switch.\n",
        "\n",
        "V4: reading in json file produced from jsonl using jsonl2json.ipynb\n",
        "\n",
        "V6: reading files from GitHub\n",
        "\n",
        "V7: using similarity function to assess the new answers \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xPDM8ocY74i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG in case of using the Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ed-1NnYIGsqj",
        "colab_type": "code",
        "outputId": "9feb9dfc-ced5-4271-bb2f-a7d8316d9159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys \n",
        "import os\n",
        "print(os.getcwd())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QByI39lkVt8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG define the foldre to inspect for files \n",
        "\n",
        "#path='/content/drive/My Drive/Colab Notebooks/'\n",
        "path=os.getcwd()+\"/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_S1byB1WPph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG read in training data\n",
        "#you may have to adjust the BATCH_SIZE acordingly \n",
        "file_name='train200.json' #or train25.json or train200.json \n",
        "\n",
        "\n",
        "file_to_read=path+file_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCUwJWTEms7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Geting the training data file \n",
        "\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "try:\n",
        "  if not Path(file_to_read).is_file():\n",
        "    file_url='https://raw.githubusercontent.com/VGGatGitHub/natural-questions/master/'+file_name\n",
        "    print(\"Will try to fetch the file from:\\n\",file_url)\n",
        "\n",
        "    response = requests.get(file_url)\n",
        "    if response.status_code == 200:\n",
        "      print('Success!')\n",
        "      s=response.content\n",
        "      # Code for printing to a file \n",
        "      sample = open(file_to_read, 'w') \n",
        "      doc=s.decode()\n",
        "      print(doc, file = sample) \n",
        "      sample.close()\n",
        "    elif response.status_code == 404:\n",
        "      print(\"Faild to find the file!\\n\",file_url)\n",
        "except Exception:\n",
        "    print(\"Exception: Faild to find or fetch the training file needed:\",file_name)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3ej-f3iYGsqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "6ef80999-48e9-470c-87b7-2b1a1d4d482a"
      },
      "source": [
        "#make sure the file you what is in the correct directory\n",
        "#some possible files are train.json or train200.json \n",
        "\n",
        "for dirname, _, filenames in os.walk(path):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/.config/.last_survey_prompt.yaml\n",
            "/content/.config/active_config\n",
            "/content/.config/.last_update_check.json\n",
            "/content/.config/gce\n",
            "/content/.config/config_sentinel\n",
            "/content/.config/.metricsUUID\n",
            "/content/.config/logs/2019.12.18/16.52.34.414154.log\n",
            "/content/.config/logs/2019.12.18/16.52.20.616768.log\n",
            "/content/.config/logs/2019.12.18/16.52.35.435000.log\n",
            "/content/.config/logs/2019.12.18/16.52.05.166856.log\n",
            "/content/.config/logs/2019.12.18/16.52.31.147337.log\n",
            "/content/.config/configurations/config_default\n",
            "/content/sample_data/README.md\n",
            "/content/sample_data/anscombe.json\n",
            "/content/sample_data/mnist_train_small.csv\n",
            "/content/sample_data/mnist_test.csv\n",
            "/content/sample_data/california_housing_train.csv\n",
            "/content/sample_data/california_housing_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS2xGhZCoFxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG\n",
        "# you may need to get the file text_utils.py from \n",
        "# https://github.com/VGGatGitHub/natural-questions\n",
        "#\n",
        "\n",
        "# sys.path.append(os.path.abspath(path))\n",
        "# from text_utils import *\n",
        "\n",
        "# got import errors on colab using import code above\n",
        "# import text_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EhFsBX5aKR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG The cell has been removed since now the data is analized in the jsonl2json.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pgXArJmIaiv",
        "colab_type": "code",
        "outputId": "38e41470-1f2e-4053-d064-4468ce43e49d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7bPY5ic2eC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (0-9, a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^0-9a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbW-oSFI2mFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG make sure the file_to_read has been defined above! \n",
        "\n",
        "UNKNOWN = \"<UNKNOWN>\"\n",
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset():\n",
        "    source = []\n",
        "    target = []\n",
        "    context = []\n",
        "\n",
        "    n_short_answers=0 #VGG\n",
        "    n_long=0\n",
        "    \n",
        "    training_for_long_answer = False #True #False \n",
        "    #make sure to run furst for shor answers and then for long...\n",
        "\n",
        "    with open(file_to_read) as json_file: #VGG\n",
        "        data = json.load(json_file)\n",
        "\n",
        "        for nq_doc in data:\n",
        "            if filename == 'train200L.json':\n",
        "              doc = simplify_nq_example(nq_doc) #VGG for jsonl formated file\n",
        "            else:\n",
        "              doc=nq_doc\n",
        "\n",
        "            question_text = doc['question_text']\n",
        "            document_text = doc['document_text'].split()\n",
        "            long_answer_candidates = doc['long_answer_candidates']\n",
        "            annotations = doc['annotations'][0]\n",
        "            \n",
        "            if annotations['long_answer']['start_token'] < annotations['long_answer']['end_token']:\n",
        "                \n",
        "                n_long+=1\n",
        "                long_answer = \" \".join(document_text[annotations['long_answer']['start_token']:\n",
        "                                                     annotations['long_answer']['end_token']])\n",
        "                                      \n",
        "                if len(annotations['short_answers']) > 0:\n",
        "                    start_token = annotations['short_answers'][0]['start_token']\n",
        "                    end_token = annotations['short_answers'][0]['end_token']\n",
        "                    short_answer = \" \".join(document_text[start_token:end_token])\n",
        "                    n_short_answers+=1 #VGG\n",
        "                else:\n",
        "                    short_answer = UNKNOWN\n",
        "                \n",
        "                #VGG V3\n",
        "                if training_for_long_answer :\n",
        "                    short_answer=long_answer #VGG V3 change - make the target to be the long answer instead of the short answer \n",
        "                    for posibilities in long_answer_candidates:\n",
        "                        if posibilities[\"top_level\"]:\n",
        "                            start_token = posibilities['start_token']\n",
        "                            end_token = posibilities['end_token']                    \n",
        "                            posibility = \" \".join(document_text[start_token:end_token])\n",
        "                            context.append(preprocess_sentence(posibility))\n",
        "                else:\n",
        "                    context.append(preprocess_sentence(long_answer))\n",
        "                #VGG context = [] #VGG it seems to work better!\n",
        "\n",
        "                source.append(preprocess_sentence(question_text))\n",
        "                target.append(preprocess_sentence(short_answer))\n",
        "#VGG                \n",
        "        print(\"Data set of:\",len(data),\" elements. It contains:\",\n",
        "              n_short_answers,\"short answers out of\", n_long,\n",
        "              \"possible long answers, short/long rate is {:.0f}%\".format(\n",
        "                  100*n_short_answers/n_long))    \n",
        "    return target, source, context\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4ecf3676-acd1-45e5-9459-3f9030b8b059",
        "_cell_guid": "3f83746e-4fa4-4e24-98cb-2f0df139a6af",
        "trusted": true,
        "id": "jevAjFFiGsqr",
        "colab_type": "code",
        "outputId": "d14ccd31-25d7-41eb-aec4-fc6bbe5be75d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "    \n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "  return tensor, lang_tokenizer\n",
        "\n",
        "def load_dataset():\n",
        "    # creating cleaned input, output pairs\n",
        "    targ_lang, inp_lang, context_lang = create_dataset()\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "    \n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n",
        "\n",
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n",
        "    \n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "    \n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights\n",
        "\n",
        "# Try experimenting with the size of that dataset\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset()\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)    \n",
        "\n",
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 1 #VGG\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 512\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)    \n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "    \n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ = tf.multiply(loss_, mask)\n",
        "  return tf.reduce_mean(loss_)\n",
        "\n",
        "\n",
        "#VGG uncommented for possible checkpoint saving later \n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)  \n",
        "\n",
        "                                 \n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "  return batch_loss\n",
        "  \n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word_index.get(i, 0) for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                           maxlen=max_length_inp,\n",
        "                                                           padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    result ='<start> '#VGG \n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result, sentence, attention_plot\n",
        "    \n",
        "#If you get error message about iretation problem -  check your BATCH_SIZE"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data set of: 200  elements. It contains: 70 short answers out of 101 possible long answers, short/long rate is 69%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OMsxPEhOGsqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "epoch=-1\n",
        "total_loss=1\n",
        "total_loss_cut=0.001*steps_per_epoch*BATCH_SIZE\n",
        "training_start_time=time.time()\n",
        "\n",
        "print(\"\\nStarting training of at most {} epochs or until total loss is les than {:0.4f}\".format(EPOCHS,total_loss_cut))\n",
        "while (epoch < EPOCHS) and (total_loss > total_loss_cut):\n",
        "  epoch+=1\n",
        "\n",
        "  start = time.time()\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch%8 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "  '''\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "  '''   \n",
        "\n",
        "  print('Epoch {} Total Loss {:.4f}'.format(epoch + 1, total_loss))\n",
        "  print('Time taken for this epoch {:.4f} sec\\n'.format(time.time() - start))\n",
        "\n",
        "print('BATCH_SIZE:{}, total training time {:.2f} minutes for {} epochs, final total_loss {:.4f}\\n'.format(\n",
        "    BATCH_SIZE,(time.time() - training_start_time)/60,epoch+1,total_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG-iceMSrYNF",
        "colab_type": "code",
        "outputId": "d172dff7-4424-4786-efe9-440e6c365db6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('BATCH_SIZE:{}, total training time {:.2f} minutes for {} epochs, final total_loss {:.4f}\\n'.format(\n",
        "    BATCH_SIZE,(time.time() - training_start_time)/60,epoch+1,total_loss))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BATCH_SIZE:1, total training time 11.72 minutes for 101 epochs, final total_loss 0.1290\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iI09zf-bGsqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    fontdict = {'fontsize': 14}\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()\n",
        "\n",
        "def ask(sentence):\n",
        "    result, sentence1, attention_plot = evaluate(sentence)\n",
        "    print('\\nQuestion: %s' % (sentence))\n",
        "    print('Predicted answer: {}'.format(result))\n",
        "    return result\n",
        "\n",
        "def show_attention_plot(sentence):\n",
        "  result, sentence1, attention_plot = evaluate(sentence)\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
        "\n",
        "def is_it_known(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "    if result.split() != ['<start>', 'unknown', '<end>']: return True\n",
        "    return False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7a7fe15c-ca68-49f0-bec9-059d7ef47e6a",
        "_cell_guid": "4684e38d-ab84-492d-8e2f-d13b1a0924fd",
        "trusted": true,
        "id": "4hRJh7EFGsqw",
        "colab_type": "code",
        "outputId": "ee319d9b-e411-483a-e378-aaea6d5a617c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "ask('which is the most common use of opt-in e-mail marketing')    \n",
        "ask('most common use of opt-in e-mail marketing')\n",
        "ask('how did I meet your mother')\n",
        "ask('who is your mother');\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question: which is the most common use of opt-in e-mail marketing\n",
            "Predicted answer: <start> march 18 , 2018 <end> \n",
            "\n",
            "Question: most common use of opt-in e-mail marketing\n",
            "Predicted answer: <start> march 18 , 2018 <end> \n",
            "\n",
            "Question: how did I meet your mother\n",
            "Predicted answer: <start> unknown <end> \n",
            "\n",
            "Question: who is your mother\n",
            "Predicted answer: <start> luis guillermo solis rivera <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkzhBscq3zWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "ff10098b-7aee-4bf4-e02c-abac7c6d95f5"
      },
      "source": [
        "show_attention_plot(\"which is the most common use of opt in e mail marketing\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnsAAAGmCAYAAAAEfEL7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nogAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VbL6X2bzGsq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "46fdf902-22a1-43d5-f637-7fe03eb89c00"
      },
      "source": [
        "show_attention_plot(\"who plays young flo in the progressive commercials\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnsAAAJaCAYAAABXxIEEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3debwkVX338c8Xhn0RcQNREyAoAsri\nCOICihsqwbgmCriL+hAVicEH40JixA2MJK6ouMYVNe4oKogCKqA8gqAsigQQAUFhEIbt9/xRNXK5\n0zNzh5m51ff05/163dd0n66u+nUx9HzvqXNOpaqQJElSm1YbugBJkiStOoY9SZKkhhn2JEmSGmbY\nkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqQZSLJNkvtNef7YJJ9MckiS\n1YesbWkMe5IkSTNzNLAjQJJ7A18GNgYOAP59wLqWyrAnSZI0M1sDP+0fPx34cVU9EdgPeNZgVS2D\nYU+SJGlmVgdu7B8/GvhG//gC4B6DVDQDhj1JkqSZOQt4WZJH0IW9Y/v2zYArB6tqGQx7kiRJM/Ma\n4MXACcCnq+rMvn1v4CdDFbUsqaqha5AkSZoT+lm3G1bV1VPa/hr4c1VdPlRdS2PYkyRJati8oQuQ\nJEnjK8ldgS2BM6pq4dD1zLYkX5nptlW196qs5Y4y7EmSpMUk2QD4MN0SIwVsBfw6yfuBy6rq0AHL\nm01/GLqAFeVlXEmStJgk7wW2p1sw+IfAA6vq10n2At5cVdsPWqBmzJ49SZI0yt7AU6rqjCRTe4bO\nAbYYqCbdAYY9SZI0yp0ZfQlzA+CWWa5lbCR5FN3dMu4DrDn1taraY5CilsF19iRJ0iin0vXuLbKo\nd+8lwMmzX87wkjwP+CZd4H0kcAVdKN4JOHuwwpbBnj1JkjTKa4FvJdmWLi8c1D/eGdht0MqG82rg\nH6vqQ0muBQ7pxzG+G1gwcG1LZM+eJElaTFWdDDyU7lLlBXS3B7sU2LWqfjpkbQPaAvhO/3ghsH7/\n+N3A84YoaCbs2ZMkSSP1twN77tB1jJE/0F3CBbgE2A74OXAXYJ2hiloWe/YkSdJikpyR5J+SbDp0\nLWPkB8Dj+sefA/4zyUeATwPHDVbVMrjOniRJWkySw+hmnd4L+D7wCeALVTW2Y9NWtSQbA2tX1aVJ\nVgP+GXgYcC7w71X1x0ELXALDniRJWqIkDweeDTwDWBf4KvCJqvr6oIVpxgx7kiRpmZLMA/YE3kR3\nN43VBy5pViTZuKquWvR4adsu2m7cOEFDkiQtVZJ70/Xu7QNsS3f7tElxRZJNq+py4EpuW29wqvTt\nYxmADXuSJGkxSe5Md+l2H7pxab8CPgn8d1VdNGRts2wPYFGP3aOGLOSO8jKuJElaTJKFdHeI+Czw\nyar62cAl6Q4y7EmSpMUkeSzw3aq6dehaxkWSZwA3VtWXp7U/GVijqo4ZprKlc509SZK0mKo6zqC3\nmEOBG0a0X9e/NpYcsydJkgBI8nNg96q6OsmZjJ6MAEBVPXD2KhsbW9CNXZzu/P61sWTYkyRJi3yB\n7p6vAGN5SXJgVwNbARdOa78vcO2sVzNDjtmTJEmagSTvAx4BPLWqzu3b7kcXkk+qqpcMWd+SGPYk\nSdJi+tuBsWjcXpJNgL2As6vq5CFrG0qSDYFvArsAv+ubNwV+AuxZVdcMVdvSGPYkSdJiknwTOLaq\njkyyPvBLYD1gfeCFVfXxQQscUD9TeYf+6c/oZi2PbaAy7EmSpMUkuQLYo6rOTPIc4P8C29MtsnzQ\npE3QSLIG3Z1DnlNVoyZpjC2XXpEkSaOsD/yxf/w44EtVdRPwPWDLwaoaSP/ZN2cpM5THlWFPkiSN\nchHwsCTrAY8HjuvbNwb+PFhVw/oY8OKhi1heLr0iSZJGeSfwCWAB8FvgxL59N+DMoYoa2HrAPv2Y\nvdPpFlP+i6p6xSBVLYNj9iRJ0khJ5gP3Bo6rqgV925OAP1bVSYMWN4Akxy/l5aqqPWatmOVg2JMk\nSTOSZI1+7JrmEMfsSZKkxSR5RZKnTXn+YeD6JL/qFxKeWEnummSXJGsNXctMGPYkSdIorwCuAEiy\nG/BM4NnAGcARA9Y1mCQbJPk8cDlwMrBZ3/7+JIcOWdvSGPYkSdIomwG/6R//LfD5qvoccCjwkKGK\nGtjbgHsCOwHXT2n/GvCUQSqaAcOeJEka5Rrg7v3jxwLf7R/fBKw9SEXD2xs4sKrO4Pbr7Z0DbDFM\nScvm0iuSJGmUbwMfTPJT4G/o7gkLsC239fhNmjsDfxjRvgFwyyzXMmP27EmSpFEOAE4C7gY8vaqu\n6tt3Aj49WFXDOpWud2+RRb17L6EbwzeWXHpFkiRpBpI8FPgW8BlgX+BDdD2dOwO7VdVPByxviezZ\nkyRJIyW5R5JXJ3lfkrv2bQ9LsvnQtQ2hqk4GHgqsCVwAPBq4FNh1XIMe2LMnSZJGSPIgukkZv6Hr\nvdq6qn7dLzFy36p69pD1aeacoCHNYf3aV6MUcANwwZRxNpK0PA4HjqyqNya5dkr7t4DnD1TTWEiy\nMd1M5dtdIa2qs4epaOkMe9LcdgK3DRBO/+fU57cm+QqwX1VdhyTN3IOAF45o/x1wj1muZSwk2RH4\nCPCARU1037mL/lx9oNKWyjF70tz2JLr1nfalWxrhb/rHvwCe1v/sALx1qAIlzVnX0y01Mt3WdHeQ\nmERHA5cAe9Bd2r4/sM2UP8eSY/akOSzJ6cDBVfXdae2PAd5WVQ9KshfwX1U1kQOqJd0xSY4CNgGe\nAVwJPJCu9+rLwPeq6lUDljeIJAuAHarq/KFrWR727Elz2zZ0v2VOdwm3/ZZ5Jt0XtiQtj1cDG9Pd\nH3dd4IfA+cAfgdcNWNeQfkjXizen2LMnzWF9z97ZwIuqamHfthbd2k/b9D17Dwc+Yc+epDsiyR50\nCymvBvy0qr4zcEmDSbIZ3ffrscBZdLeO+4uqOnGIupbFCRrS3PZ/gK8ClyQ5q2/bDrgV2Kt/vgXw\n3gFqkzRHJVmDrhfrOVX1PeB7A5c0LrYCdgQeP+K1sZ2gYc+e5owkqwFU1a39803oAs05VXXSkLUN\nKcl6dJMy7tc3/RL4VFUtGK4qSXNdksuBh1fVuUPXMi6S/IrulmlvAX7PbasfAFBVo+6bOzjDnuaM\nJN8Ejq2qI5OsTxdq1gPWB15YVR8ftEBJakiSdwBU1T8PXcu4SHId8MCqumDoWpaHl3E1l8wHDu4f\nPxW4Btgc2IduIPFEhr0k9wJ2Y/QCn+8cpChJLVgP2CfJY4HTgdut1VlVrxikqmEdR7f+oGFPWkXW\np5sFBvA44EtVdVOS7wHvGa6s4STZh27dp5vpZsxN7aovwLAn6Y66P7Dofq9bTHttUi8LHgsckeSB\ndCsdTJ+g8cVBqloGL+NqzujHSryRbkLChcAzquqEJDsAx1XV3YasbwhJLgA+C7y+qm4Zuh5JalmS\nW5fyclXVWE7QsGdPc8k7gU8AC4DfAoumuO9G9xvWJLoH8CGDniStelU1J9cnNuxpzqiqD/Tryt2b\nridv0W9YFwCvH66yQX0D2AX49dCFSGpLkuMZfbm2gBvoFlj+WFX9dMQ2GiNexh1z/azT8ib2kGSH\nqjpj6DrGSZIX0wXdjzOHxo9IGn9J3gs8G7gM+Enf/GC6O/L8D7A98ABgz+m3bGxZkh2BRzF6UtzB\nI980MMPemEpyAPAaYLO+6WK6e51O7OK4/ViJn9GtXv6pqvrTwCUNbq6OH5E0/pK8E1itqg6c1n4E\n3ffLq5McCexcVbsOUuQsS3Iw8Fa6oUTT19mrqnroIIUtg2FvDCV5LXAIcDjdCuYAjwAOAg6rqrcO\nVduQkmwFvADYD7gz8CXgw1V1/KCFSVKDkvwBeEhVnTet/b7AKVV1lyTbASdV1Z0GKXKWJfkdcGhV\nfWDoWpbHnBxoOAFeCuxfVf9aVd/tfw4FXtb/TKSqOq+qDgHuAzwTWBs4NskFSf6lX29OkrRyBNh2\nRPs2/WsAN9LdnnFSrAbMuUvW9uyNoSQ3ANtV1fnT2rcCzqyqtYepbLwkWZsu/L4FWJNurbkvAv9U\nVZcMWdtsSXLQ0l53UWVJd1SS/wCeQ3fZ8tS++cF0Q4w+XlUH9eOGn1NVjxiozFmV5FBgjar6l6Fr\nWR6GvTGU5OfAMVX1b9Pa3wg8taq2H6ay8ZBkZ7rLuX9PdxeNj9AtLLwp8G/AxlX14OEqnD1JfjOt\naQ2683A9cHlVTV8IVZJmJMnqwD8Dr6CblAHdZI0jgcOr6pYk9wFuraqLBypzViUJ3SoImwBnsfik\nuBcMUdeyGPbGUJKnAp8DTgBO6psfBuxOt5Dw/wxU2qD6XqznA/cFvk43UePYKUuwLLp12IVVNbHL\nCiW5B10A/mBVfWnoeqS5IMldgS2BM6pq4dD1jJskGwJU1TVD1zKkJIfR9Wz+lMUnaFBVfztEXcti\n2BtTSR4EvIrudjUA5wBHVNXPhqtqWEnOAz4MfKSqfr+EbdYEnlVVH5vV4sZMvzTA56pqq6FrkcZZ\nkg3ovleeTvcP91ZV9esk7wcu68dLT7QkW9CN0yvg7KqafkVhYiT5I/CSqvrs0LUsD8Oe1KD+l4Xj\nq2rDoWuRxlm/ltz2wAF0qx88sA97ewFvnuRhM31v3oeBp3HbJIwAXwBeWFXXDlXbUPrZuLtX1blD\n17I8JvZS11yQ5J6MXrRxolcr78/LfegmZfxFVZ04+h3t6i/5366JbszeAcAPZr8iac7ZG3hKVZ2R\nZGrvxznApI95PRJ4IN0Cwif3bQ8D3g+8C3jhQHUN6T+AA5McUHOot8yevTHUX4L7JLA1t01vX2Ri\nF8rtQ96n6dYcLLpz85e/wJN4XkYsqlzAFcD36GYl/272q5LmjiTXAQ/oe/OuBbbvH+8AnFBVGw1c\n4mD6dfb+rqp+MK19N+BLVXWXYSobTpKv0t2P/Y/A2Sw+QWPvIepaFnv2xtNRwP8CLwYuZfS9CSfR\nu+iWV9mGbhmAPYF70M3AfdWAdQ1mrt6UWxojp9L17r2rf77o+/Yl3NabNanWAf4wov0qunVOJ9GV\ndEt8zSn27I2h/jfNHefamIBVLcnvgSdV1WlJrgHmV9W5SZ4EvL6qHjJwiRoj/azkA5gysBx475Im\n92gyJXko8C3gM8C+dLP8twV2Bnab5GEzSY6jW95qv6r6c9+2Ht29uDesqscOWZ9mzl6B8XQmt61p\npNusQ/dbFXS/Wd69f3w23biSiZTkSUlOTHJlkiuSfD/JE4eua0hJHgacT3cT9+uBG4B9gPOSTMQ9\nPDUzVXUy8FC6McAXAI+mu6Ky6yQHvd5BwEOAS/rvle/TXXXaBThwqe9sXJItkuzVf/+O/dhOe/bG\nRJKNpzzdATgMeB1d8Js+JuCqWSxtbCT5CfCGqjo2yf8AC4B/AV4OPHkSlxlJ8iLgvcB/c/v7KD8L\neFlVHT1UbUNKcgrd/zsvXbQOY5LV6AaWbzeuNyuXxk2Sdel+Udq6bzoH+O+qun64qoYzV2coG/bG\nRD/Qfup/jEUTM6a3TfIEjX3oblPz0SQ7AccCdwEWAs+tqs8PWuAA+rUHj6yqd09rfznw8qq67zCV\nDSvJ9cAOVfWrae1bAz+rqnWGqUzjytUPbi/JGnQTBV9bVRcMXc+4SPIRup7g/Vl8hvJJVTWWM5QN\ne2Miye4z3baqvr8qa5kr+t84twYuqqorl7V9i5IsBLYdcR/lvwF+UVVrDVPZsJJcBjyvqo6d1v4E\n4Oiq2nSYyjRuXP1gyZJcDTyoqn49dC3jYq7OUHY27piYGuCSfJvuVmknAD+pqpsHKmus9QOGJ/K3\n7ikuAh5LNz5tqscBv539csbGZ4APJzmY2//2/Ta65XukRVz9YMm+CDwVOHzoQsbInJyhbNgbTz8G\nngC8AbipH390AhMY/pL850y3rapXrMpaxtThwH/1l7Wnhpr96MYyTqqD6Xppjua277mbgPcB/3eo\nosZFkr+nm4gw6rLlWK4Ttgptg6sfLMlFwOuSPAI4Dbhu6otV9c5BqhrWScCbkkyfofyvjPFSPV7G\nHWNJ1qEbG/DI/mcX4IZJugVWkuNnuGlV1R6rtJgxleQpwD9x+/sov6OqvjxcVeOhv9S/Zf/0gkVf\nzpMsyTvoZlIez4ierKp6/hB1DSXJj4CDJ/EOPMuSZGn3wK2qGvtZqCtbkgfQjRdfF/h53/wAuln/\nj6uqXwxV29IY9sZYv07YI4E96G5Xcy/gx1X1qCHrGgdJ1geoqgVD1zKkflbyh4BvLJp1Ki1Nv17l\nAVV1zNC1DMXVD5af37m3mYszlL2MO4b6G3M/Evgruku636cbT/Kjqlo4YGmDS3Ig3dpPm/XPLwXe\nCbxrLt2ncCW6Dvgs8KckH6WbfDB9/N5ESPKVmW47gZcqp1oNOGPoIgZ2JYuvdPDtEW0FTOwEDfA7\nd7okbwb+t6reP639pUk2q6rXD1TaUtmzN4b6ZViuAN4NfBM4fRL/p5ouydvppru/Azilb94VeDXw\nwao6eKjahtSv+7QP8HxgPt16ex8CPj/Ov2mubP0lp5OBG5e17aRdqpyq/8fqpqo6dOhahjJt9YO/\nppugccu0zVYD7lNVH5utusaN37mLS3IR8Iyq+vG09p3pvnP/apjKls6wN4aSbMlt4/R2Bzag+wf8\neLobc0/kDNQkVwH7T7/8lOTpwAfGdcr7bEqyLfAi4KV06w9+lu438HMGLWwW9L8kbVJVlyf5NfDg\nqho1a26iJXkP3Z1FzqYbczT9suVETXRKcguwaVVdPq39LsDlE770it+50yS5Adhm+nI0/V00zq6q\nsZyR62XcMdQvYHkB3SrdixaCPRh4K90lhYn98uG2AbHT2yb+1n/9orBPBvYCbqZb0f3ewM+THFJV\nrS+fcBWwOXA5XW/NxP+dWIJtuO0y7tZL23BCLLpcO936dLfZm3R+597eRXR3KZq+9uBuwMWzX87M\nGPbGUH9bp/l0kzIeSbeUxtrA6XTLr0yqj9Pd2P6V09pfBnxi9ssZXr/K/ZOBF9Ctt/cz4O3ApxcN\npE6yN925az3sfQE4sR9TVMBpfa/NYiZxFuEiTvDqTFnWqYC3JJk6U3t1YGcc2+h37uI+APxHkjWB\n7/VtjwbeQreO51jyMu4YSnINsBbdgsEn9D8/rKrrlvK25iV5H93lp98BP+qbdwHuSXdv2L+sPzgp\nl6KSXEnXM/EpujE0i/0WnmQjuluEbT7b9c2mJAGeCGxFN4D834CR96msqiNmsbTB9ZNX9q2qa5Yx\nkaWq6smzVdeQpizrtDvdeLSpYz1vBC4EDq+q82a5tLHhd+5oSd5Ct3zRmn3TjXS3rRzbNTwNe2Mo\nyeMx3C3GNfcWl2Q/ukHBXm6aor9/5SvG9abks23q+egfL9GkTV7pz8crq+qaoWsZN37nLlm/kPI2\n/dNzxn1JGsOeJElSwyZ1gKUkSdJEMOzNAUn2H7qGceR5Gc3zMprnZXGek9E8L6N5XkabC+fFsDc3\njP1fpIF4XkbzvIzmeVmc52Q0z8tonpfRxv68GPYkSZIa5gSNJVhz9XVqnXl3GroMAG685c+sufq6\nQ5cxdsblvNywyXgtV3nLgutYff31hi4DbsnQFdzOrdddx2rrDX9e1rpkfCbZ38RC1mCtocsYO56X\n0Twvo43LebmWq6+sqruNem28/pUaI+vMuxMP3WyfocvQHHD2wZsMXcJYmnftJN/oZcm2eM0py95I\nkpbTd+qY3y7pNS/jSpIkNcywJ0mS1DDDniRJUsMMe5IkSQ0z7EmSJDXMsCdJktQww54kSVLDDHuS\nJEkNM+xJkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPsSZIkNcywJ0mS1DDDniRJUsMMe5IkSQ0z7EmS\nJDXMsCdJktQww54kSVLDDHuSJEkNM+xJkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPsSZIkNcywJ0mS\n1DDDniRJUsMMe5IkSQ0z7EmSJDVsVsNeko8m+dpK3N8JSd69svYnSZLUmpUS9pJsmGSjlbGvGR5v\nXpIs5fX7zFYtkiRJ4+wOh70kqyd5fJJPAZcB2/ftL0lybpIbklyZ5Ft9ODsUeC7wpCTV/zyyf89b\nk/wqyfVJLkzy9iRrTznWoUnOSvK8JBcAC4HPA7sDB0zZ31/3b/lNku8meW6S9e/oZ5QkSZrr5i3v\nG5JsSxfa9gXWpQtdewI/SDIfeE//+g+BjYA9+rceDtwf2BjYr2+7qv/zOuAFwCXANsD76QLd66cc\nenPg2cAzgBuB/wXuCfwSeG2/zRX9n9v0x/hX4D1JvgB8DDihqm5d3s8sSZI0V80o7CW5C7APXYh7\nAHAs8Ergq1V1w5Tt7kMX3L5SVdcCvwX+X//ygiTXAwur6rKp+6+qN015emGSw4BXc/uwtyawX1X9\nfsrxbgT+PGJ/vwJel+T1wG50we+LwDVJPgF8rKrOHfE59wf2B1h79Q1mcmokSZLG2kx79l4OvBE4\nGbhvVV24hO2Oowt4v0nyLeDbwBf74LdESZ4OHAj8DbA+sHr/M9XFU4PeTFRVAd8Hvp/klcB/0vUC\nPgx45IjtjwKOArjTWpvU8hxLkiRpHM10zN5RwOuAuwJnJflEkscluV0g60PdTsAzgYuAQ4BfJrnn\nknac5CHAZ4BvAX8L7Ngfa41pm143w1qn73+HJEcA5wF7A/9F1yspSZLUvBmFvaq6tKreXFX3Ax4D\nLKALaBcnOSLJDlO2vbmqvldVhwAPBNYD9upfvpHFe+weBlxSVW+qqlOr6jzgr2ZY/6j9keReSQ5O\ncibwY7rxfv8HuGdVvaKq/t/090iSJLVouSdoVNWPgB8lOZCuJ+65wKlJ9gDuBGwJnEg3+eJRwAbA\nOf3bLwSekOR+wB+APwHnApsl2Qc4BXg88KwZlnMhsHM/C3cBcFU/AeO3wOl0Ez0+XVVXLWkHkiRJ\nLVvusLdIVS0EjgGOSXJ34Ba62bZ/B7yBbqbuBcCLquoH/ds+SDdW7jS6sXmPqqqvJnkH8C5gHbpx\nfm8A3juDMg6nm2V7dv/ezekC4LZV9cs7+tkkSZJakW4Og6a701qb1EM322foMjQHnH3wJkOXMJbm\nXbvYCAsBW7zmlKFLkNSg79Qxp1fV/FGveW9cSZKkhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ\n9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmSGmbY\nkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElqmGFP\nkiSpYYY9SZKkhhn2JEmSGmbYkyRJati8oQsYVwvvtgbnvWSzocsYOxts94ehSxg727z04qFLGEs3\nX3Lp0CVIkrBnT5IkqWmGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElq\nmGFPkiSpYYY9SZKkhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlh\nhj1JkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ\n9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqSGrbSwl+SjSb62svYnSZKkFTdvJe7rlUBW4v4kSZK0glZa\n2KuqP62sfUmSJGnlWCWXcZOsleRdSX6f5IYkP0ry8Cnbrp7kw0l+k+T6JOclOTjJatP3l+SVSS5J\ncnWSjyRZd8o2JyR5b5LDklyZ5PIkh0/bz75JTk1ybf/655NstrI+tyRJ0jhbVRM03g78PfACYEfg\nTODYJJtOOe4lwDOB+wP/ArwWeP60/TwC2A54TL+/p9BdLp5qH+Bm4KHAPwIH9tsusibwRmB7YC/g\nrsCnV/QDSpIkzQUrc8weAEnWA14GvKiqvt63vRTYAzgAeF1V3QS8YcrbLkyyE/As4MNT2q8BXlpV\ntwDnJPk88GjgLVO2ObuqFu3r3CQv7rf5NEBVHT1l218neVm/r3tV1cXTat8f2B9g3kZ3vsPnQJIk\naVysip69LYE1gJMWNfRh7RRgm0VtSV6a5LQkVyRZALwKuM+0fZ3dv3eRS4G7T9vm59Oe326bJDsl\n+XKS3ya5Fjitf2n6saiqo6pqflXNX3299WbyWSVJksbabK+zVwBJ/h54F/BR4PHADsB76S65TnXT\niPdPr3mJ2/S9jN8C/gzsBzwY2LPfbvqxJEmSmrPSL+MCFwA3Ag/rH5NkdWBX4FP9Ng8HflxV7170\npiRbroJatqYbo/faqvpNf5ynroLjSJIkjaWV3rNXVdcB7wPeluSJSe7fP78HXe8dwLnATkmekGSr\nJK8Hdl/ZtQAXAQuBf0yyRZInAW9aBceRJEkaS6vqMu5rgM8CHwHOAB4I7FlVv+tf/wDwObqevlOB\nvwaOWNlFVNUVwHOBvwPOppuVe9DKPo4kSdK4SlWtnB0ln+739w8rZYcDW/te9657vfxVQ5cxdjbY\n7g9DlzB2NnnpgqFLGEs3X3Lp0CVI0sT4Th1zelXNH/XaCvfsJZmXZBu6MXlnrej+JEmStPKsjMu4\n29EtZ/IL4D0rYX+SJElaSVZ4Nm5VnQGsu8wNJUmSNOtme509SZIkzSLDniRJUsMMe5IkSQ0z7EmS\nJDXMsCdJktQww54kSVLDDHuSJEkNM+xJkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPsSZIkNcywJ0mS\n1DDDniRJUsMMe5IkSQ0z7EmSJDXMsCdJktQww54kSVLDDHuSJEkNM+xJkiQ1zLAnSZLUMMOeJElS\nwwx7kiRJDTPsSZIkNWze0AWMqzWvKe7zrYVDlzF2vvPczw1dwth5/CU7DF2CJElLZM+eJElSwwx7\nkiRJDTPsSZIkNcywJ0mS1DDDniRJUsMMe5IkSQ0z7EmSJDXMsCdJktQww54kSVLDDHuSJEkNM+xJ\nkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPsSZIkNcywJ0mS1DDDniRJUsMMe5IkSQ0z7EmSJDXMsCdJ\nktQww54kSVLDDHuSJEkNMwjS5psAAA79SURBVOxJkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPsSZIk\nNcywJ0mS1DDDniRJUsMMe5IkSQ0z7EmSJDXMsCdJktSwiQl76fxTkvOSLExycZK3DF2XJEnSqjRv\n6AJm0WHAy4CDgBOBuwE7DlqRJEnSKjYRYS/J+sCrgAOr6ui++XzglGnb7Q/sD7DWWhvNao2SJEmr\nwqRcxt0GWAv47tI2qqqjqmp+Vc1fc831ZqcySZKkVWhSwp4kSdJEmpSwdw6wEHj00IVIkiTNpokY\ns1dV1yY5EnhLkoV0EzTuAjyoqt43bHWSJEmrzkSEvd4hwNXA64F7Ab8HPj5oRZIkSavYxIS9qroV\neGv/I0mSNBEmZcyeJEnSRDLsSZIkNcywJ0mS1DDDniRJUsMMe5IkSQ0z7EmSJDXMsCdJktQww54k\nSVLDDHuSJEkNM+xJkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPsSZIkNcywJ0mS1DDDniRJUsMMe5Ik\nSQ0z7EmSJDXMsCdJktQww54kSVLDDHuSJEkNM+xJkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPsSZIk\nNcywJ0mS1LB5Qxcwtm4p5l1309BVjJ0999536BLGzlVfu3HoEsbS+u++09AljKU1jz116BIkTRh7\n9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmSGmbY\nkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElqmGFP\nkiSpYYY9SZKkhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1J\nkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmSGmbYkyRJaphhT5IkqWGGvSmS7J/ktCSn\n3XTzdUOXI0mStMIMe1NU1VFVNb+q5q8xb72hy5EkSVphhj1JkqSGGfYkSZIaNnFhL8k/Jvnl0HVI\nkiTNhokLe8BdgfsNXYQkSdJsmLiwV1WHVlWGrkOSJGk2TFzYkyRJmiSGPUmSpIYZ9iRJkhpm2JMk\nSWqYYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmSGmbYkyRJaphhT5Ik\nqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKk\nhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ9iRJkho2b+gCxtbq4eb11xi6irHz9U9+YOgSxs7e\n937I0CWMp1tvGboCSRL27EmSJDXNsCdJktQww54kSVLDDHuSJEkNM+xJkiQ1zLAnSZLUMMOeJElS\nwwx7kiRJDTPsSZIkNcywJ0mS1DDDniRJUsMMe5IkSQ0z7EmSJDXMsCdJktQww54kSVLDDHuSJEkN\nM+xJkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPsSZIkNcywJ0mS1DDDniRJUsMMe5IkSQ0z7EmSJDXM\nsCdJktQww54kSVLDDHuSJEkNM+xJkiQ1zLAnSZLUsDkT9pI8MkkluevQtUiSJM0VcybsAScDmwJ/\nGLoQSZKkuWLe0AXMVFXdCFw2dB2SJElzyaz17CVZL8nHkyxI8vskhyT5WpKP9q/fOcnHklyd5Pok\n30my7ZT33+4ybpLn9ft6dJKzklyX5Pgkm0877iH98Rb0x39jkgtn63NLkiQNaTYv4x4B7A48BdgD\n2B54xJTXPwrsAjwZ2Bn4M3BsknWWss+1gEOAFwC7AhsB71/0YpJ/AN4I/AuwE3AOcNBK+TSSJElz\nwKxcxk2yPl0ge05VHde3vRC4uH+8FbA3sHtVndi37QdcBOwDfGgJu54HHFBVv+rfczhwdJJUVQGv\nBD5aVYve/5YkjwLuu4Q69wf2B1hrrY1W7ENLkiSNgdnq2dsSWAP4yaKGqroOOKt/en/gVuCUKa//\nCTgT2GYp+124KOj1LgXWBO7cP9966jF7P17SzqrqqKqaX1Xz11xzvaV+IEmSpLlgLszGraW8dvMS\ntp0Ln0uSJGmVm61QdAFwE/DgRQ1J1gW265+e09ey65TXNwQeAJy9Asf95dRj9nZegf1JkiTNKbMy\nZq+qFiQ5GnhbkiuB3wGvowt4VVXnJfky8IF+3NwfgTcD1wCfWoFDHwl8JMmpwA/oJofsAly9AvuU\nJEmaM2Zznb1XA+sBXwEWAP8B3AO4oX/9+cC7+tfXBk4C9qyq6+/oAavqM0m2AN4KrAt8kW627pPv\n6D4lSZLmklkLe1W1ANiv/yHJWsCBwDf6168GnruU958AZMrzj9It17LEbfq2w4DDFj1P8iXg/Dv+\nSSRJkuaOWQt7SXakm3X7E2AD4DX9n59dhcdcF3gZcCzdZI6n0fXqPW1VHVOSJGmczPbt0g4C7kcX\nvM4Adquqi1fh8Qp4AvBaYB3gPGDfqvrSKjymJEnS2JjNy7g/A+bP1vH6Y14PPGY2jylJkjROXI9O\nkiSpYYY9SZKkhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1J\nkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ9iRJ\nkhpm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElq2LyhCxhb1/6Z1Y//6dBVjJ29N3vw0CWM\noVuGLkCSpCWyZ0+SJKlhhj1JkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmSGmbYkyRJ\naphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElqmGFPkiSp\nYYY9SZKkhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqSG\nGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKkhs35sJfk1UkuHLoOSZKkcTTnw54kSZKWbJWGvSQbJtlo\nVR5jxDHvlmTt2TymJEnSuFrpYS/J6kken+RTwGXA9n37nZIcleTyJNcm+X6S+VPe97wkC5I8OslZ\nSa5LcnySzaft/+Akl/XbfhxYf1oJTwQu64/1sJX9+SRJkuaSlRb2kmyb5O3A/wKfBa4D9gROTBLg\n68BmwF7AjsCJwPeSbDplN2sBhwAvAHYFNgLeP+UYzwT+HXgjsBPwK+CgaaX8N/BsYAPguCTnJ3nD\n9NAoSZI0CVYo7CW5S5JXJDkd+BmwNfBKYJOqenFVnVhVBTwK2AF4elX9pKrOr6rXA78G9puyy3nA\nAf02PwcOBx7Zh0WAA4GPVdUHqurcqnoz8JOpNVXVzVX1jap6FrAJcFh//POSnJDkBUmm9wYu+jz7\nJzktyWk3sXBFTo0kSdJYWNGevZcDRwI3APetqr2r6vNVdcO07R4ErAtc0V9+XZBkAbAdsOWU7RZW\n1a+mPL8UWBO4c//8/sAp0/Y9/flfVNU1VXV0VT0KeDBwD+DDwNOXsP1RVTW/quavwVpL+diSJElz\nw7wVfP9RwE3Ac4CzknwJ+ATw3aq6Zcp2qwG/Bx4xYh/XTHl887TXasr7l1uSteguG+9LN5bvF3S9\ng1++I/uTJEmaa1aoZ6+qLq2qN1fV/YDHAAuAzwAXJzkiyQ79pj+l61W7tb+EO/Xn8uU45DnAQ6a1\n3e55Og9P8gG6CSL/BZwPPKiqdqqqI6vq6uX/tJIkSXPPSpugUVU/qqqXAZvSXd69L3BqkkcA3wFO\nAr6c5AlJNk+ya5J/7V+fqSOB5yZ5cZKtkhwC7DJtm32BbwMbAs8C7l1V/1xVZ63gR5QkSZpzVvQy\n7mKqaiFwDHBMkrsDt1RVJXki3UzaDwJ3p7usexLw8eXY92eTbAG8mW4M4FeAdwLPm7LZd+kmiFyz\n+B4kSZImS7rJsppuw2xcu+TRQ5chSZK0TN+pY06vqvmjXvN2aZIkSQ0z7EmSJDXMsCdJktQww54k\nSVLDDHuSJEkNM+xJkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPsSZIkNcywJ0mS1DDDniRJUsMMe5Ik\nSQ0z7EmSJDXMsCdJktQww54kSVLDDHuSJEkNM+xJkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPsSZIk\nNcywJ0mS1DDDniRJUsMMe5IkSQ0z7EmSJDXMsCdJktQww54kSVLDDHuSJEkNM+xJkiQ1zLAnSZLU\nMMOeJElSwwx7kiRJDTPsSZIkNcywJ0mS1DDDniRJUsMMe5IkSQ0z7EmSJDXMsCdJktQww54kSVLD\nDHuSJEkNM+xJkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPsSZIkNcywJ0mS1DDDniRJUsMMe5IkSQ0z\n7EmSJDXMsCdJktQww54kSVLDDHuSJEkNM+xJkiQ1zLAnSZLUMMOeJElSwwx7kiRJDTPsSZIkNcyw\nJ0mS1DDDniRJUsMMe5IkSQ0z7EmSJDVs3tAFjJMk+wP7A6zNugNXI0mStOLs2Zuiqo6qqvlVNX8N\n1hq6HEmSpBVm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmS\nGmbYkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlhhj1JkqSGGfYkSZIaZtiTJElq\nmGFPkiSpYYY9SZKkhhn2JEmSGmbYkyRJaphhT5IkqWGGPUmSpIYZ9iRJkhpm2JMkSWqYYU+SJKlh\nhj1JkqSGGfYkSZIaZtiTJElqmGFPkiSpYYY9SZKkhhn2JEmSGmbYkyRJaliqaugaxlKSK4DfDl1H\n767AlUMXMYY8L6N5XkbzvCzOczKa52U0z8to43Je/qqq7jbqBcPeHJDktKqaP3Qd48bzMprnZTTP\ny+I8J6N5XkbzvIw2F86Ll3ElSZIaZtiTJElqmGFvbjhq6ALGlOdlNM/LaJ6XxXlORvO8jOZ5GW3s\nz4tj9iRJkhpmz54kSVLDDHuSJEkNM+xJkiQ1zLAnSZLUMMOeJElSw/4/Oo/gd2tR07EAAAAASUVO\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEdV3whqoTty",
        "colab_type": "code",
        "outputId": "c018efc5-f7cf-423d-d301-d03f058c97b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_md\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_fGaAGKoVLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy as sp\n",
        "nlp = sp.load(\"en_core_web_md\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IigyUmaoX3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test the similarity measure and get some idea about the output values \n",
        "\n",
        "# sample text\n",
        "messages = [\n",
        "# Smartphones\n",
        "\"My phone is not good.\",\n",
        "\"Your cellphone looks great.\",\n",
        "# Weather\n",
        "\"Will it snow tomorrow?\",\n",
        "\"Recently a lot of hurricanes have hit the US\",\n",
        "# Food and health\n",
        "\"An apple a day, keeps the doctors away\",\n",
        "\"Eating strawberries is healthy\"\n",
        "]\n",
        "\n",
        "for text1 in messages:\n",
        "  doc1 = nlp(text1)\n",
        "  print()\n",
        "  for text2 in messages:\n",
        "    doc2 = nlp(text2)\n",
        "    print(doc1.similarity(doc2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iRhZwdJrWPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e223589-63af-41d1-ac6c-5d2707cf4958"
      },
      "source": [
        "target, source, context = create_dataset()\n",
        "\n",
        "print(\"\\ngoing over all the questions and selecting those with answers ... \\n\")\n",
        "\n",
        "n_answers=0\n",
        "i=-1\n",
        "n_correct=0\n",
        "n_smlr=0\n",
        "smlrty_cut=85\n",
        "for question_text in source:\n",
        "    i+=1\n",
        "    TheAnswer=target[i]\n",
        "    TheAnswer=TheAnswer.replace('<start>',' ')\n",
        "    TheAnswer=TheAnswer.replace('<end>',' ')\n",
        "    doc1 = nlp(TheAnswer)\n",
        "    if is_it_known(question_text):\n",
        "        n_answers+=1\n",
        "        AFanswer=ask(question_text)\n",
        "        AFanswer=AFanswer.replace('<start>',' ')\n",
        "        AFanswer=AFanswer.replace('<end>',' ')\n",
        "        doc2 = nlp(AFanswer)\n",
        "        if AFanswer.split() == TheAnswer.split(): \n",
        "          n_correct+=1\n",
        "        else:\n",
        "          smlrty=100*doc1.similarity(doc2)\n",
        "          if smlrty > smlrty_cut: n_smlr+=1\n",
        "          print(\"The answer was:\",target[i])\n",
        "          print(\"Similarity:{:0.2f}%\\n\".format(smlrty))\n",
        "\n",
        "print(\"\\n{} answers out of {} possible, rate is {:.0f}%\".format(n_answers,len(source),100*n_answers/len(source)))\n",
        "if n_answers >0:\n",
        "  print(\"At least {} correct answers out of {} possible, rate is {:.0f}%\".format(n_correct,n_answers,100*n_correct/n_answers))\n",
        "if n_smlr >0:\n",
        "  print(\"There were {} similar answers with  similarity above {}%\\n\".format(n_smlr,smlrty_cut))\n",
        "           "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data set of: 200  elements. It contains: 70 short answers out of 101 possible long answers, short/long rate is 69%\n",
            "\n",
            "going over all the questions and selecting those with answers ... \n",
            "\n",
            "\n",
            "Question: <start> when is the last episode of season 8 of the walking dead <end>\n",
            "Predicted answer: <start> march 18 , 2018 <end> \n",
            "\n",
            "Question: <start> in greek mythology who was the goddess of spring growth <end>\n",
            "Predicted answer: <start> persephone p r s f ni greek , also called kore k ri the maiden <end> \n",
            "\n",
            "Question: <start> what is the name of the most important jewish text <end>\n",
            "Predicted answer: <start> the shulchan aruch <end> \n",
            "\n",
            "Question: <start> what is the name of spain s most famous soccer team <end>\n",
            "Predicted answer: <start> real madrid <end> \n",
            "\n",
            "Question: <start> when was the first robot used in surgery <end>\n",
            "Predicted answer: <start> 1983 <end> \n",
            "\n",
            "Question: <start> who sings the song i don t care i love it <end>\n",
            "Predicted answer: <start> icona pop and charli xcx <end> \n",
            "\n",
            "Question: <start> who are uncle owen and aunt beru related to <end>\n",
            "Predicted answer: <start> shmi <end> \n",
            "\n",
            "Question: <start> where is zimbabwe located in the world map <end>\n",
            "Predicted answer: <start> in southern africa , botswana , zambia and mozambique <end> \n",
            "The answer was: <start> in southern africa , between the zambezi and limpopo rivers , bordered by south africa , botswana , zambia and mozambique <end>\n",
            "Similarity:94.24%\n",
            "\n",
            "\n",
            "Question: <start> 100 acres is equal to how many hectares <end>\n",
            "Predicted answer: <start> 1 square hectometre hm <end> \n",
            "\n",
            "Question: <start> where was donovan mitchell picked in the draft <end>\n",
            "Predicted answer: <start> 13th <end> \n",
            "\n",
            "Question: <start> who is the president of costa rica 2017 <end>\n",
            "Predicted answer: <start> luis guillermo solis rivera <end> \n",
            "\n",
            "Question: <start> when did power rangers tv show come out <end>\n",
            "Predicted answer: <start> in 2010 <end> \n",
            "The answer was: <start> august 28 , 1993 <end>\n",
            "Similarity:59.64%\n",
            "\n",
            "\n",
            "Question: <start> how many beverly hills cops movies are there <end>\n",
            "Predicted answer: <start> three <end> \n",
            "\n",
            "Question: <start> who holds the most women s wimbledon titles <end>\n",
            "Predicted answer: <start> martina navratilova <end> \n",
            "\n",
            "Question: <start> where does jinx you owe me a coke come from <end>\n",
            "Predicted answer: <start> irish origin <end> \n",
            "The answer was: <start> jinx is a children s game with varying rules and penalties that occur when two people unintentionally speak the same word or phrase simultaneously <end>\n",
            "Similarity:38.40%\n",
            "\n",
            "\n",
            "Question: <start> where does the last name hickey come from <end>\n",
            "Predicted answer: <start> irish origin <end> \n",
            "\n",
            "Question: <start> where is the greatest royal rumble taking place <end>\n",
            "Predicted answer: <start> jeddah , saudi arabia <end> \n",
            "\n",
            "Question: <start> who sang my name is tallulah in bugsy malone <end>\n",
            "Predicted answer: <start> louise liberty williams <end> \n",
            "\n",
            "Question: <start> what is andy s sisters name in toy story <end>\n",
            "Predicted answer: <start> the shulchan aruch <end> \n",
            "The answer was: <start> molly <end>\n",
            "Similarity:19.37%\n",
            "\n",
            "\n",
            "Question: <start> who sings with shaggy on it wasn me <end>\n",
            "Predicted answer: <start> english jamaican singer rikrok <end> \n",
            "\n",
            "Question: <start> what is the largest catholic high school in america <end>\n",
            "Predicted answer: <start> st . francis preparatory school <end> \n",
            "\n",
            "Question: <start> who established the peoples republic of china in 1949 <end>\n",
            "Predicted answer: <start> mao zedong <end> \n",
            "\n",
            "Question: <start> who sang take that look off your face <end>\n",
            "Predicted answer: <start> jackie ward <end> \n",
            "The answer was: <start> marti webb <end>\n",
            "Similarity:49.87%\n",
            "\n",
            "\n",
            "Question: <start> who plays percy in the lost city of z <end>\n",
            "Predicted answer: <start> charlie hunnam <end> \n",
            "\n",
            "Question: <start> is stone cold steve austin in the longest yard <end>\n",
            "Predicted answer: <start> luis guillermo solis rivera <end> \n",
            "The answer was: <start> unknown <end>\n",
            "Similarity:1.14%\n",
            "\n",
            "\n",
            "Question: <start> who plays the first lady on house of cards <end>\n",
            "Predicted answer: <start> joanna c . going <end> \n",
            "\n",
            "Question: <start> who owns st andrews golf course in scotland <end>\n",
            "Predicted answer: <start> the st andrews links trust <end> \n",
            "\n",
            "Question: <start> at the center of the storm george tenet <end>\n",
            "Predicted answer: <start> at sea level 765 mmhg in arterial blood is between 35 mmhg and 45 mmhg in arterial blood is between 35 mmhg and 45 mmhg in arterial blood is between \n",
            "The answer was: <start> unknown <end>\n",
            "Similarity:38.16%\n",
            "\n",
            "\n",
            "Question: <start> which city and state hosts the annual college world series <end>\n",
            "Predicted answer: <start> the commission <end> \n",
            "The answer was: <start> omaha , nebraska <end>\n",
            "Similarity:26.59%\n",
            "\n",
            "\n",
            "Question: <start> who is ted talking about in how i met your mother <end>\n",
            "Predicted answer: <start> tracy mcconnell <end> \n",
            "\n",
            "Question: <start> when does grey s anatomy season 14 premiere <end>\n",
            "Predicted answer: <start> september 28 , 2017 <end> \n",
            "\n",
            "Question: <start> the partial pressure of carbon dioxide in arterial blood is approximately <end>\n",
            "Predicted answer: <start> at sea level 765 mmhg in arterial blood is between 35 mmhg and 45 mmhg <end> \n",
            "\n",
            "Question: <start> what was uncle jesse s original last name on full house <end>\n",
            "Predicted answer: <start> icona pop and charli xcx <end> \n",
            "The answer was: <start> cochran <end>\n",
            "Similarity:44.23%\n",
            "\n",
            "\n",
            "Question: <start> who pays the judgements on the judge mathis show <end>\n",
            "Predicted answer: <start> greg mathis <end> \n",
            "\n",
            "Question: <start> who made up the elf on the shelf <end>\n",
            "Predicted answer: <start> chanda bell <end> \n",
            "\n",
            "Question: <start> who warned concord that the british were coming <end>\n",
            "Predicted answer: <start> samuel prescott <end> \n",
            "\n",
            "Question: <start> who lasted the longest on alone season 2 <end>\n",
            "Predicted answer: <start> david mcintyre <end> \n",
            "\n",
            "Question: <start> where is the us military base in japan <end>\n",
            "Predicted answer: <start> yokota air base , fussa , western tokyo <end> \n",
            "\n",
            "Question: <start> who determines the size of the supreme court <end>\n",
            "Predicted answer: <start> congress <end> \n",
            "\n",
            "Question: <start> who is the actor that plays lucifer on tv <end>\n",
            "Predicted answer: <start> thomas john ellis <end> \n",
            "\n",
            "Question: <start> who designed the national coat of arms of south africa <end>\n",
            "Predicted answer: <start> iaan bekker <end> \n",
            "\n",
            "Question: <start> when does model code of conduct come into force <end>\n",
            "Predicted answer: <start> immediately on announcement of the election schedule by the commission <end> \n",
            "\n",
            "Question: <start> when did now thats what i call music come out <end>\n",
            "Predicted answer: <start> 28 november 1983 <end> \n",
            "\n",
            "Question: <start> where is the 2018 grey cup being played <end>\n",
            "Predicted answer: <start> the brick field at commonwealth stadium in edmonton , alberta <end> \n",
            "\n",
            "Question: <start> where did the band bastille get their name <end>\n",
            "Predicted answer: <start> bastille day <end> \n",
            "\n",
            "Question: <start> where is arkansas river located on a map <end>\n",
            "Predicted answer: <start> the arkansas river flows through colorado , kansas , oklahoma , and arkansas , and arkansas , and arkansas , and arkansas , and arkansas , and arkansas , and \n",
            "The answer was: <start> the arkansas river flows through colorado , kansas , oklahoma , and arkansas , and its watershed also drains parts of texas , new mexico and missouri . <end>\n",
            "Similarity:95.19%\n",
            "\n",
            "\n",
            "Question: <start> who plays nicholas in the princess diaries 2 <end>\n",
            "Predicted answer: <start> joanna c . going <end> \n",
            "The answer was: <start> chris pine <end>\n",
            "Similarity:50.56%\n",
            "\n",
            "\n",
            "Question: <start> what is the population of st . john s newfoundland <end>\n",
            "Predicted answer: <start> the shulchan aruch <end> \n",
            "The answer was: <start> unknown <end>\n",
            "Similarity:13.65%\n",
            "\n",
            "\n",
            "Question: <start> the p wave phase of an electrocardiogram ecg represents <end>\n",
            "Predicted answer: <start> at sea level 765 mmhg in arterial blood is between 35 mmhg and 45 mmhg in arterial blood is between 35 mmhg and 45 mmhg in arterial blood is between \n",
            "The answer was: <start> atrial depolarization <end>\n",
            "Similarity:29.74%\n",
            "\n",
            "\n",
            "Question: <start> when did star trek the next generation first air <end>\n",
            "Predicted answer: <start> september 28 , 1987 <end> \n",
            "\n",
            "Question: <start> why was the civil rights act of 1866 made into an amendment to the constitution <end>\n",
            "Predicted answer: <start> 1983 <end> \n",
            "The answer was: <start> unknown <end>\n",
            "Similarity:14.32%\n",
            "\n",
            "\n",
            "Question: <start> who sang the most wonderful summer of my life <end>\n",
            "Predicted answer: <start> jackie ward <end> \n",
            "\n",
            "Question: <start> how many oscars did on golden pond win <end>\n",
            "Predicted answer: <start> three <end> \n",
            "\n",
            "Question: <start> how many episodes on queen of the south season 1 <end>\n",
            "Predicted answer: <start> 13 <end> \n",
            "\n",
            "Question: <start> who is the existing prime minister of pakistan <end>\n",
            "Predicted answer: <start> imran khan <end> \n",
            "\n",
            "Question: <start> who is known as the father of texas <end>\n",
            "Predicted answer: <start> stephen fuller austin <end> \n",
            "\n",
            "Question: <start> what is the orange stuff on my sushi <end>\n",
            "Predicted answer: <start> the shulchan aruch <end> \n",
            "The answer was: <start> tobiko <end>\n",
            "Similarity:7.96%\n",
            "\n",
            "\n",
            "Question: <start> when did nsw last won a state of origin series <end>\n",
            "Predicted answer: <start> 2018 <end> \n",
            "\n",
            "Question: <start> when does life is strange before the storm part 2 <end>\n",
            "Predicted answer: <start> october 2017 <end> \n",
            "\n",
            "Question: <start> where is sodom and gomorrah located in the bible <end>\n",
            "Predicted answer: <start> the brick field at commonwealth stadium in edmonton , kansas , zambia and mozambique <end> \n",
            "The answer was: <start> on the jordan river plain in the southern region of the land of canaan <end>\n",
            "Similarity:76.44%\n",
            "\n",
            "\n",
            "Question: <start> what is the longest non medical word in the dictionary <end>\n",
            "Predicted answer: <start> the shulchan aruch <end> \n",
            "The answer was: <start> unknown <end>\n",
            "Similarity:13.65%\n",
            "\n",
            "\n",
            "Question: <start> when did the xbox 360 slim come out <end>\n",
            "Predicted answer: <start> in 2010 <end> \n",
            "\n",
            "Question: <start> who spread the theory that one is a product of the mind and body <end>\n",
            "Predicted answer: <start> luis guillermo solis rivera <end> \n",
            "The answer was: <start> rene descartes <end>\n",
            "Similarity:53.36%\n",
            "\n",
            "\n",
            "Question: <start> how many goals scored ronaldo in his career <end>\n",
            "Predicted answer: <start> over 670 <end> \n",
            "\n",
            "Question: <start> who played tess on touched by an angel <end>\n",
            "Predicted answer: <start> delloreese patricia early july 6 , 1931 november 19 , 2017 , known professionally as della reese <end> \n",
            "\n",
            "Question: <start> when did the hornets move to new orleans <end>\n",
            "Predicted answer: <start> 2002 03 season <end> \n",
            "\n",
            "Question: <start> what is the capital of bulgaria on a map <end>\n",
            "Predicted answer: <start> the shulchan aruch <end> \n",
            "The answer was: <start> unknown <end>\n",
            "Similarity:13.65%\n",
            "\n",
            "\n",
            "Question: <start> fish appeared in the fossil record during the <end>\n",
            "Predicted answer: <start> persephone p r s f ni greek , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 , \n",
            "The answer was: <start> the cambrian explosion <end>\n",
            "Similarity:16.13%\n",
            "\n",
            "\n",
            "Question: <start> who died from the band faith no more <end>\n",
            "Predicted answer: <start> singer chuck mosley <end> \n",
            "\n",
            "Question: <start> who signed the gun control act of 1968 <end>\n",
            "Predicted answer: <start> president lyndon b . johnson <end> \n",
            "\n",
            "Question: <start> where do frankenstein and the monster first meet <end>\n",
            "Predicted answer: <start> the mountains <end> \n",
            "\n",
            "Question: <start> the human tendency to mimic other people s behavior is an example of <end>\n",
            "Predicted answer: <start> march 18 , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 , 2017 \n",
            "The answer was: <start> mirroring <end>\n",
            "Similarity:3.61%\n",
            "\n",
            "\n",
            "Question: <start> when does season five of the killing come out <end>\n",
            "Predicted answer: <start> a fourth season consisting of six episodes to conclude the series <end> \n",
            "\n",
            "Question: <start> how is the head of the church of england <end>\n",
            "Predicted answer: <start> the monarch is the supreme governor <end> \n",
            "\n",
            "74 answers out of 101 possible, rate is 73%\n",
            "At least 53 correct answers out of 74 possible, rate is 72%\n",
            "There were 2 similar answers with  similarity above 85%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXQ0s6F9nsH9",
        "colab_type": "code",
        "outputId": "1382ce29-d286-43d6-cd3d-1498d537115e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "target, source, context = create_dataset()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data set of: 200  elements. It contains: 70 short answers out of 101 possible long answers, short/long rate is 69%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyw_WyJB0tZ5",
        "colab_type": "code",
        "outputId": "2a4bbf85-311d-4d0d-80dd-ba070fff5ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(\"Short Answer training results:\")\n",
        "print(\"\\n{} answers out of {} possible, rate is {:.0f}%\".format(n_answers,len(source),100*n_answers/len(source)))\n",
        "if n_answers >0:\n",
        "  print(\"At least {} correct answers out of {} possible, rate is {:.0f}%\".format(n_correct,n_answers,100*n_correct/n_answers))\n",
        "if n_smlr >0:\n",
        "  print(\"There were {} similar answers with  similarity above {}%\\n\".format(n_smlr,smlrty_cut))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Short Answer training results:\n",
            "\n",
            "74 answers out of 101 possible, rate is 73%\n",
            "At least 53 correct answers out of 74 possible, rate is 72%\n",
            "There were 2 similar answers with  similarity above 85%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w3K2RVX1AuD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d90e5ece-09ca-4b56-b066-2cdfe6812191"
      },
      "source": [
        "print(\"Long Answer training results:\")\n",
        "print(\"\\n{} answers out of {} possible, rate is {:.0f}%\".format(n_answers,len(source),100*n_answers/len(source)))\n",
        "if n_answers >0:\n",
        "  print(\"At least {} correct answers out of {} possible, rate is {:.0f}%\".format(n_correct,n_answers,100*n_correct/n_answers))\n",
        "if n_smlr >0:\n",
        "  print(\"There were {} similar answers with  similarity above {}%\\n\".format(n_smlr,smlrty_cut))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Long Answer training results:\n",
            "\n",
            "74 answers out of 101 possible, rate is 73%\n",
            "At least 53 correct answers out of 74 possible, rate is 72%\n",
            "There were 2 similar answers with  similarity above 85%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}